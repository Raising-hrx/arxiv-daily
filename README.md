# arxiv-daily
 Automated deployment @ 2025-04-07 17:29:59 Asia/Shanghai
> Welcome to contribute! Add your topics and keywords in [`topic.yml`](https://github.com/beiyuouo/arxiv-daily/blob/main/database/topic.yml).
> You can also view historical data through the [storage](https://github.com/beiyuouo/arxiv-daily/blob/main/database/storage).

## Pre-training

### Pre-training
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-03-11**|**7ABAW-Compound Expression Recognition via Curriculum Learning**|Chen Liu et.al.|[2503.07969v1](http://arxiv.org/abs/2503.07969v1)|null|
|**2025-02-17**|**Continual Quantization-Aware Pre-Training: When to transition from 16-bit to 1.58-bit pre-training for BitNet language models?**|Jacob Nielsen et.al.|[2502.11895v1](http://arxiv.org/abs/2502.11895v1)|null|
|**2025-02-17**|**Towards Efficient Pre-training: Exploring FP4 Precision in Large Language Models**|Jiecheng Zhou et.al.|[2502.11458v1](http://arxiv.org/abs/2502.11458v1)|null|
|**2025-01-09**|**Advancing ALS Applications with Large-Scale Pre-training: Dataset Development and Downstream Assessment**|Haoyi Xiu et.al.|[2501.05095v1](http://arxiv.org/abs/2501.05095v1)|[link](https://github.com/martianxiu/als_pretraining)|
|**2024-12-26**|**Improving Generative Pre-Training: An In-depth Study of Masked Image Modeling and Denoising Models**|Hyesong Choi et.al.|[2412.19104v1](http://arxiv.org/abs/2412.19104v1)|null|
|**2024-12-06**|**APOLLO: SGD-like Memory, AdamW-level Performance**|Hanqing Zhu et.al.|[2412.05270v4](http://arxiv.org/abs/2412.05270v4)|[link](https://github.com/zhuhanqing/APOLLO)|
|**2024-11-14**|**Self-Supervised Radio Pre-training: Toward Foundational Models for Spectrogram Learning**|Ahmed Aboulfotouh et.al.|[2411.09849v1](http://arxiv.org/abs/2411.09849v1)|null|
|**2024-11-14**|**Long-Tailed Object Detection Pre-training: Dynamic Rebalancing Contrastive Learning with Dual Reconstruction**|Chen-Long Duan et.al.|[2411.09453v1](http://arxiv.org/abs/2411.09453v1)|null|
|**2024-10-30**|**$100K or 100 Days: Trade-offs when Pre-Training with Academic Resources**|Apoorv Khandelwal et.al.|[2410.23261v1](http://arxiv.org/abs/2410.23261v1)|[link](https://github.com/apoorvkh/academic-pretraining)|
|**2024-09-25**|**Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale**|Fan Zhou et.al.|[2409.17115v2](http://arxiv.org/abs/2409.17115v2)|[link](https://github.com/gair-nlp/prox)|
|**2024-08-19**|**Image-based Freeform Handwriting Authentication with Energy-oriented Self-Supervised Learning**|Jingyao Wang et.al.|[2408.09676v1](http://arxiv.org/abs/2408.09676v1)|null|
|**2024-07-29**|**Enhancing CTR Prediction through Sequential Recommendation Pre-training: Introducing the SRP4CTR Framework**|Ruidong Han et.al.|[2407.19658v1](http://arxiv.org/abs/2407.19658v1)|null|
|**2024-06-28**|**TabSketchFM: Sketch-based Tabular Representation Learning for Data Discovery over Data Lakes**|Aamod Khatiwada et.al.|[2407.01619v3](http://arxiv.org/abs/2407.01619v3)|[link](https://github.com/ibm/tabsketchfm)|
|**2024-06-20**|**Instruction Pre-Training: Language Models are Supervised Multitask Learners**|Daixuan Cheng et.al.|[2406.14491v2](http://arxiv.org/abs/2406.14491v2)|[link](https://github.com/microsoft/lmops)|
|**2024-06-06**|**Pointer-Guided Pre-Training: Infusing Large Language Models with Paragraph-Level Contextual Awareness**|Lars Hillebrand et.al.|[2406.04156v1](http://arxiv.org/abs/2406.04156v1)|[link](https://github.com/LarsHill/pointer-guided-pre-training)|
|**2024-05-22**|**Text-Free Multi-domain Graph Pre-training: Toward Graph Foundation Models**|Xingtong Yu et.al.|[2405.13934v4](http://arxiv.org/abs/2405.13934v4)|null|
|**2024-04-02**|**Dynamic Pre-training: Towards Efficient and Scalable All-in-One Image Restoration**|Akshay Dudhane et.al.|[2404.02154v2](http://arxiv.org/abs/2404.02154v2)|[link](https://github.com/akshaydudhane16/dynet)|
|**2024-04-01**|**Large Motion Model for Unified Multi-Modal Motion Generation**|Mingyuan Zhang et.al.|[2404.01284v1](http://arxiv.org/abs/2404.01284v1)|null|
|**2024-02-29**|**Always be Pre-Training: Representation Learning for Network Intrusion Detection with GNNs**|Zhengyao Gu et.al.|[2402.18986v1](http://arxiv.org/abs/2402.18986v1)|null|
|**2024-02-15**|**Efficient Language Adaptive Pre-training: Extending State-of-the-Art Large Language Models for Polish**|Szymon Ruciński et.al.|[2402.09759v1](http://arxiv.org/abs/2402.09759v1)|null|
|**2024-01-26**|**Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective**|Yue Xing et.al.|[2401.15248v1](http://arxiv.org/abs/2401.15248v1)|null|
|**2023-11-12**|**PuzzleTuning: Explicitly Bridge Pathological and Natural Image with Puzzles**|Tianyi Zhang et.al.|[2311.06712v4](http://arxiv.org/abs/2311.06712v4)|[link](https://github.com/sagizty/puzzletuning)|
|**2023-11-07**|**Topology Only Pre-Training: Towards Generalised Multi-Domain Graph Models**|Alex O. Davies et.al.|[2311.03976v4](http://arxiv.org/abs/2311.03976v4)|[link](https://github.com/neutralpronoun/general-gcl)|
|**2023-11-02**|**Better with Less: A Data-Active Perspective on Pre-Training Graph Neural Networks**|Jiarong Xu et.al.|[2311.01038v2](http://arxiv.org/abs/2311.01038v2)|[link](https://github.com/galina0217/apt)|
|**2023-10-25**|**Enhancing Document Information Analysis with Multi-Task Pre-training: A Robust Approach for Information Extraction in Visually-Rich Documents**|Tofik Ali et.al.|[2310.16527v1](http://arxiv.org/abs/2310.16527v1)|null|
|**2023-10-10**|**Utilizing Synthetic Data for Medical Vision-Language Pre-training: Bypassing the Need for Real Images**|Che Liu et.al.|[2310.07027v2](http://arxiv.org/abs/2310.07027v2)|[link](https://github.com/cheliu-computation/medsyn-replearn)|
|**2023-10-02**|**Harnessing the Power of Multi-Lingual Datasets for Pre-training: Towards Enhancing Text Spotting Performance**|Alloy Das et.al.|[2310.00917v4](http://arxiv.org/abs/2310.00917v4)|[link](https://github.com/alloydas/testr_eval)|
|**2023-09-28**|**Attention Sorting Combats Recency Bias In Long Context Language Models**|Alexander Peysakhovich et.al.|[2310.01427v1](http://arxiv.org/abs/2310.01427v1)|null|
|**2023-08-29**|**Characterizing Learning Curves During Language Model Pre-Training: Learning, Forgetting, and Stability**|Tyler A. Chang et.al.|[2308.15419v2](http://arxiv.org/abs/2308.15419v2)|[link](https://github.com/tylerachang/lm-learning-curves)|
|**2023-06-29**|**Stop Pre-Training: Adapt Visual-Language Models to Unseen Languages**|Yasmine Karoui et.al.|[2306.16774v1](http://arxiv.org/abs/2306.16774v1)|[link](https://github.com/yasminekaroui/clicotea)|

## Reasoning

### Reasoning
|Publish Date|Title|Authors|PDF|Code|
| :---: | :---: | :---: | :---: | :---: |
|**2025-04-04**|**MME-Unify: A Comprehensive Benchmark for Unified Multimodal Understanding and Generation Models**|Wulin Xie et.al.|[2504.03641v1](http://arxiv.org/abs/2504.03641v1)|null|
|**2025-04-04**|**Bonsai: Interpretable Tree-Adaptive Grounded Reasoning**|Kate Sanders et.al.|[2504.03640v1](http://arxiv.org/abs/2504.03640v1)|null|
|**2025-04-04**|**Do Larger Language Models Imply Better Reasoning? A Pretraining Scaling Law for Reasoning**|Xinyi Wang et.al.|[2504.03635v1](http://arxiv.org/abs/2504.03635v1)|null|
|**2025-04-04**|**Nemotron-H: A Family of Accurate and Efficient Hybrid Mamba-Transformer Models**|NVIDIA et.al.|[2504.03624v1](http://arxiv.org/abs/2504.03624v1)|null|
|**2025-04-04**|**EnrichIndex: Using LLMs to Enrich Retrieval Indices Offline**|Peter Baile Chen et.al.|[2504.03598v1](http://arxiv.org/abs/2504.03598v1)|null|
|**2025-04-04**|**Target Prediction Under Deceptive Switching Strategies via Outlier-Robust Filtering of Partially Observed Incomplete Trajectories**|Yiming Meng et.al.|[2504.03502v1](http://arxiv.org/abs/2504.03502v1)|null|
|**2025-04-04**|**Verified Program Extraction in Number Theory: The Fundamental Theorem of Arithmetic and Relatives**|Franziskus Wiesnet et.al.|[2504.03460v1](http://arxiv.org/abs/2504.03460v1)|null|
|**2025-04-04**|**ZFusion: An Effective Fuser of Camera and 4D Radar for 3D Object Perception in Autonomous Driving**|Sheng Yang et.al.|[2504.03438v1](http://arxiv.org/abs/2504.03438v1)|null|
|**2025-04-04**|**Optimizing Quantum Circuits via ZX Diagrams using Reinforcement Learning and Graph Neural Networks**|Alexander Mattick et.al.|[2504.03429v1](http://arxiv.org/abs/2504.03429v1)|null|
|**2025-04-04**|**Online Difficulty Filtering for Reasoning Oriented Reinforcement Learning**|Sanghwan Bae et.al.|[2504.03380v1](http://arxiv.org/abs/2504.03380v1)|null|
|**2025-04-04**|**SoK: Attacks on Modern Card Payments**|Xenia Hofmeier et.al.|[2504.03363v1](http://arxiv.org/abs/2504.03363v1)|null|
|**2025-04-04**|**Detecting Stereotypes and Anti-stereotypes the Correct Way Using Social Psychological Underpinnings**|Kaustubh Shivshankar Shejole et.al.|[2504.03352v1](http://arxiv.org/abs/2504.03352v1)|null|
|**2025-04-04**|**Evaluating Compact LLMs for Zero-Shot Iberian Language Tasks on End-User Devices**|Luís Couto Seller et.al.|[2504.03312v1](http://arxiv.org/abs/2504.03312v1)|null|
|**2025-04-04**|**Do Large Language Models Solve the Problems of Agent-Based Modeling? A Critical Review of Generative Social Simulations**|Maik Larooij et.al.|[2504.03274v1](http://arxiv.org/abs/2504.03274v1)|null|
|**2025-04-04**|**Seeing is Believing: Belief-Space Planning with Foundation Models as Uncertainty Estimators**|Linfeng Zhao et.al.|[2504.03245v1](http://arxiv.org/abs/2504.03245v1)|null|
|**2025-04-04**|**Think When You Need: Self-Adaptive Chain-of-Thought Learning**|Junjie Yang et.al.|[2504.03234v1](http://arxiv.org/abs/2504.03234v1)|null|
|**2025-04-04**|**Weak instrumental variables due to nonlinearities in panel data: A Super Learner Control Function estimator**|Monika Avila Marquez et.al.|[2504.03228v1](http://arxiv.org/abs/2504.03228v1)|null|
|**2025-04-04**|**Explain with Visual Keypoints Like a Real Mentor! A Benchmark for Multimodal Solution Explanation**|Jaewoo Park et.al.|[2504.03197v1](http://arxiv.org/abs/2504.03197v1)|null|
|**2025-04-04**|**2026 ESPPU input from the ANUBIS Collaboration**|Oleg Brandt et.al.|[2504.03195v1](http://arxiv.org/abs/2504.03195v1)|null|
|**2025-04-04**|**Learning Sparse Disentangled Representations for Multimodal Exclusion Retrieval**|Prachi et.al.|[2504.03184v1](http://arxiv.org/abs/2504.03184v1)|null|
|**2025-04-04**|**Graphiti: Bridging Graph and Relational Database Queries**|Yang He et.al.|[2504.03182v1](http://arxiv.org/abs/2504.03182v1)|null|
|**2025-04-04**|**Do Developers Depend on Deprecated Library Versions? A Mining Study of Log4j**|Haruhiko Yoshioka et.al.|[2504.03167v1](http://arxiv.org/abs/2504.03167v1)|null|
|**2025-04-04**|**NuScenes-SpatialQA: A Spatial Understanding and Reasoning Benchmark for Vision-Language Models in Autonomous Driving**|Kexin Tian et.al.|[2504.03164v1](http://arxiv.org/abs/2504.03164v1)|null|
|**2025-04-04**|**Why Reasoning Matters? A Survey of Advancements in Multimodal Reasoning (v1)**|Jing Bi et.al.|[2504.03151v1](http://arxiv.org/abs/2504.03151v1)|null|
|**2025-04-04**|**LightPROF: A Lightweight Reasoning Framework for Large Language Model on Knowledge Graph**|Tu Ao et.al.|[2504.03137v1](http://arxiv.org/abs/2504.03137v1)|null|
|**2025-04-04**|**Les Dissonances: Cross-Tool Harvesting and Polluting in Multi-Tool Empowered LLM Agents**|Zichuan Li et.al.|[2504.03111v1](http://arxiv.org/abs/2504.03111v1)|null|
|**2025-04-03**|**Unlocking the AMD Neural Processing Unit for ML Training on the Client Using Bare-Metal-Programming Tools**|André Rösti et.al.|[2504.03083v1](http://arxiv.org/abs/2504.03083v1)|null|
|**2025-04-03**|**LLM Library Learning Fails: A LEGO-Prover Case Study**|Ian Berlot-Attwell et.al.|[2504.03048v1](http://arxiv.org/abs/2504.03048v1)|null|
|**2025-04-03**|**AuDeRe: Automated Strategy Decision and Realization in Robot Planning and Control via LLMs**|Yue Meng et.al.|[2504.03015v1](http://arxiv.org/abs/2504.03015v1)|null|
|**2025-04-03**|**Language Models Guidance with Multi-Aspect-Cueing: A Case Study for Competitor Analysis**|Amir Hadifar et.al.|[2504.02984v1](http://arxiv.org/abs/2504.02984v1)|null|
